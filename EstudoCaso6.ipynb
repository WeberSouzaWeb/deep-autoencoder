{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Deep Learning Para Aplicações de IA com PyTorch e Lightning</font>\n",
    "\n",
    "## <font color='blue'>Estudo de Caso 6</font>\n",
    "## <font color='blue'>Sistema de Similaridade de Imagens com Deep Autoencoders</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DSA](imagens/EC6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalando e Carregando os Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.10.9\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_CPP_MIN_LOG_LEVEL=3\n"
     ]
    }
   ],
   "source": [
    "%env TF_CPP_MIN_LOG_LEVEL=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch==2.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchvision==0.15.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pytorch-lightning==2.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_rgb\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Weber Souza\n",
      "\n",
      "torchvision      : 0.15.2\n",
      "matplotlib       : 3.7.0\n",
      "json             : 2.0.9\n",
      "numpy            : 1.23.5\n",
      "pytorch_lightning: 2.0.3\n",
      "torch            : 2.0.1\n",
      "seaborn          : 0.12.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Weber Souza\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga e Processamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta de dados\n",
    "DATASET_PATH = \"dados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasta dos modelos\n",
    "CHECKPOINT_PATH = \"modelos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações aplicadas em cada imagem\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dados/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 170498071/170498071 [12:10<00:00, 233392.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dados/cifar-10-python.tar.gz to dados\n"
     ]
    }
   ],
   "source": [
    "# Carregando o conjunto de dados de treinamento. \n",
    "imagens_treino = CIFAR10(root = DATASET_PATH, \n",
    "                         train = True, \n",
    "                         transform = transform, \n",
    "                         download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide os dados de treino em treino e validação\n",
    "dataset_treino, dataset_valid = torch.utils.data.random_split(imagens_treino, [45000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Carregando o conjunto de dados de teste\n",
    "dataset_teste = CIFAR10(root = DATASET_PATH, \n",
    "                        train = False, \n",
    "                        transform = transform, \n",
    "                        download = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora definimos os dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_treino = data.DataLoader(dataset_treino, \n",
    "                                batch_size = 256, \n",
    "                                shuffle = True, \n",
    "                                drop_last = True, \n",
    "                                pin_memory = True, \n",
    "                                num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_valid = data.DataLoader(dataset_valid, \n",
    "                               batch_size = 256, \n",
    "                               shuffle = False, \n",
    "                               drop_last = False, \n",
    "                               num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_teste = data.DataLoader(dataset_teste, \n",
    "                               batch_size = 256, \n",
    "                               shuffle = False, \n",
    "                               drop_last = False, \n",
    "                               num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter uma imagem\n",
    "def get_train_images(num):\n",
    "    return torch.stack([imagens_treino[i][0] for i in range(num)], dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo o Modelo \n",
    "\n",
    "Em geral, um autoencoder consiste em um **encoder** que mapeia a entrada $x$ para um vetor de recursos de menor dimensão $z$ e um **decoder** que reconstrói a entrada $\\hat{x}$ de $z$. \n",
    "\n",
    "Treinamos o modelo comparando $x$ com $\\hat{x}$ e otimizando os parâmetros para aumentar a similaridade entre $x$ e $\\hat{x}$. Veja abaixo uma pequena ilustração da estrutura do autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center width=\"100%\"><img src=\"imagens/autoencoder_visualization.svg\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"650px\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificador (Encoder)\n",
    "\n",
    "Primeiro começamos implementando o codificador. O codificador consiste efetivamente em uma rede convolucional profunda, onde reduzimos a escala da imagem camada por camada usando convoluções escalonadas. Depois de reduzir a escala da imagem três vezes, achatamos os recursos e aplicamos camadas lineares. A representação latente $z$ é, portanto, um vetor de tamanho *d*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificador\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_input_channels : int, \n",
    "                 base_channel_size : int, \n",
    "                 latent_dim : int, \n",
    "                 act_fn : object = nn.GELU):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        c_hid = base_channel_size\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            # https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "            # 32x32 => 16x16\n",
    "            nn.Conv2d(num_input_channels, \n",
    "                      c_hid, \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1, \n",
    "                      stride = 2), \n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            nn.Conv2d(c_hid, \n",
    "                      c_hid, \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1),\n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            # 16x16 => 8x8\n",
    "            nn.Conv2d(c_hid, \n",
    "                      2*c_hid, \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1, \n",
    "                      stride = 2), \n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            nn.Conv2d(2*c_hid, \n",
    "                      2*c_hid, \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1),\n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            # 8x8 => 4x4\n",
    "            nn.Conv2d(2*c_hid, \n",
    "                      2*c_hid, \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1, \n",
    "                      stride = 2), \n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(2*16*c_hid, \n",
    "                      latent_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que não aplicamos a normalização em lote aqui. Isso ocorre porque queremos que a codificação de cada imagem seja independente de todas as outras imagens. Caso contrário, podemos introduzir correlações na codificação ou decodificação, o que não queremos ter. \n",
    "\n",
    "Em algumas implementações ainda é possível ver a Batch Normalization sendo utilizada, pois ela também pode servir como uma forma de regularização. No entanto, a melhor prática é usar outras técnicas de normalização, se necessário, como normalização de instância ou normalização de camada. Dado o pequeno tamanho do modelo, podemos negligenciar a normalização por enquanto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decodificador (Decoder)\n",
    "\n",
    "O decodificador é uma versão espelhada e invertida do codificador. A única diferença é que substituímos as convoluções strided por convoluções transpostas (ou seja, deconvoluções) para melhorar os recursos. \n",
    "\n",
    "As convoluções transpostas podem ser imaginadas como adicionando o passo à entrada em vez da saída e, portanto, podem aumentar a escala da entrada. Para uma ilustração de uma camada `nn.ConvTranspose2d` com tamanho de kernel 3, passo 2 e preenchimento 1, veja abaixo (fonte da imagem - [Vincent Dumoulin and Francesco Visin](https://arxiv.org/abs/1603.07285)):\n",
    "\n",
    "<center width=\"100%\"><img src=\"imagens/deconvolution.gif\" width=\"250px\"></center>\n",
    "\n",
    "Você vê que para uma entrada de tamanho $3\\times3$, obtemos uma saída de $5\\times5$. No entanto, para realmente ter uma operação reversa da convolução, precisamos garantir que a camada dimensione a forma de entrada por um fator de 2 (por exemplo, $4\\times4\\to8\\times8$). Para isso, podemos especificar o parâmetro `output_padding` que adiciona valores adicionais à forma de saída. Observe que não executamos preenchimento com zeros com isso, mas aumentamos a forma de saída para cálculo.\n",
    "\n",
    "Em geral, o decodificador pode ser implementado da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificador\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_input_channels : int, \n",
    "                 base_channel_size : int, \n",
    "                 latent_dim : int, \n",
    "                 act_fn : object = nn.GELU):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        c_hid = base_channel_size\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 2*16*c_hid), # input vetor latent\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            \n",
    "            # 4x4 => 8x8\n",
    "            nn.ConvTranspose2d(2*c_hid, \n",
    "                               2*c_hid, \n",
    "                               kernel_size = 3, \n",
    "                               output_padding = 1, \n",
    "                               padding = 1, \n",
    "                               stride = 2), \n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            nn.Conv2d(2*c_hid, \n",
    "                      2*c_hid, \n",
    "                      kernel_size = 3, \n",
    "                      padding = 1),\n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            # 8x8 => 16x16\n",
    "            nn.ConvTranspose2d(2*c_hid, \n",
    "                               c_hid, \n",
    "                               kernel_size = 3, \n",
    "                               output_padding = 1, \n",
    "                               padding = 1, \n",
    "                               stride = 2), \n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            nn.Conv2d(c_hid, c_hid, kernel_size = 3, padding = 1),\n",
    "            \n",
    "            act_fn(),\n",
    "            \n",
    "            # 16x16 => 32x32\n",
    "            nn.ConvTranspose2d(c_hid, \n",
    "                               num_input_channels, \n",
    "                               kernel_size = 3, \n",
    "                               output_padding = 1, \n",
    "                               padding = 1, \n",
    "                               stride = 2), \n",
    "            \n",
    "            # As imagens de entrada são dimensionadas entre -1 e 1, portanto, a saída também deve ser limitada\n",
    "            nn.Tanh() \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.reshape(x.shape[0], -1, 4, 4)\n",
    "        x = self.net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As redes de codificador e decodificador que escolhemos aqui são relativamente simples. Normalmente, redes mais complexas são aplicadas, especialmente quando se usa uma arquitetura baseada em ResNet. Por exemplo, consulte [VQ-VAE](https://arxiv.org/abs/1711.00937) e [NVAE](https://arxiv.org/abs/2007.03898) (embora os artigos discutam arquiteturas para Variational Autoencoders, eles podem ser igualmente aplicados a Deep Autoencoders)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção dos Módulos com Lightning - Deep Autoencoder\n",
    "\n",
    "Em uma etapa final, adicionamos o codificador e o decodificador juntos na arquitetura do Deep Autoencoder. Definimos o modelo como PyTorch Lightning Module para simplificar o código de treinamento necessário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAutoencoder\n",
    "class DeepAutoencoder(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 base_channel_size: int, \n",
    "                 latent_dim: int, \n",
    "                 encoder_class : object = Encoder,\n",
    "                 decoder_class : object = Decoder,\n",
    "                 num_input_channels: int = 3, \n",
    "                 width: int = 32, \n",
    "                 height: int = 32):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Salvando os hiperparâmetros\n",
    "        self.save_hyperparameters() \n",
    "        \n",
    "        # Criando encoder e decoder\n",
    "        self.encoder = encoder_class(num_input_channels, base_channel_size, latent_dim)\n",
    "        self.decoder = decoder_class(num_input_channels, base_channel_size, latent_dim)\n",
    "        \n",
    "        # Exemplo de matriz de entrada necessária para visualizar o gráfico da rede\n",
    "        self.example_input_array = torch.zeros(2, num_input_channels, width, height)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "    \n",
    "    def _get_reconstruction_loss(self, batch):\n",
    "        x, _ = batch \n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.mse_loss(x, x_hat, reduction = \"none\")\n",
    "        loss = loss.sum(dim=[1,2,3]).mean(dim = [0])\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr = 1e-3)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \n",
    "                                                         mode = 'min', \n",
    "                                                         factor = 0.2, \n",
    "                                                         patience = 20, \n",
    "                                                         min_lr = 5e-5)\n",
    "        \n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)                             \n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log('val_loss', loss)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log('test_loss', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a função de perda, usamos o erro quadrático médio (MSE). O erro quadrático médio leva a rede a prestar atenção especial aos valores de pixel cuja estimativa está distante. Prever 127 em vez de 128 não é importante ao reconstruir, mas confundir 0 com 128 é muito pior. Observe que, ao contrário dos VAEs, não prevemos a probabilidade por valor de pixel, mas usamos uma medida de distância. Isso economiza muitos parâmetros e simplifica o treinamento. Para obter uma melhor intuição por pixel, relatamos o erro quadrado somado sobre a dimensão do lote (qualquer outra média/soma leva ao mesmo resultado/parâmetros).\n",
    "\n",
    "No entanto, MSE também tem algumas desvantagens consideráveis. Normalmente, o MSE leva a imagens borradas onde pequenos ruídos/padrões de alta frequência são removidos, pois causam um erro muito baixo. \n",
    "\n",
    "Para garantir imagens realistas a serem reconstruídas, pode-se combinar Generative Adversarial Networks com Autoencoders como feito em vários trabalhos (por exemplo, veja [aqui](https://arxiv.org/abs/1704.02304), [aqui](https://arxiv.org/abs/1511.05644) ou estes [slides](http://elarosca.net/slides/iccv_autoencoder_gans.pdf)). \n",
    "\n",
    "Além disso, comparar duas imagens usando MSE não reflete necessariamente sua semelhança visual. Por exemplo, suponha que o modelo reconstrói uma imagem deslocada em um pixel para a direita e para baixo. Embora as imagens sejam quase idênticas, podemos obter uma perda maior do que prever um valor de pixel constante para metade da imagem (veja o código abaixo). Uma solução de exemplo para esse problema inclui o uso de uma CNN separada e pré-treinada e o uso de uma distância de recursos visuais em camadas inferiores como uma medida de distância em vez da comparação original em nível de pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Função para comparar imagens\n",
    "def compare_imgs(img1, img2, title_prefix=\"\"):\n",
    "\n",
    "    loss = F.mse_loss(img1, img2, reduction = \"sum\")\n",
    "\n",
    "    grid = torchvision.utils.make_grid(torch.stack([img1, img2], dim = 0), nrow = 2, normalize = True, range = (-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.title(f\"{title_prefix} Loss: {loss.item():4.2f}\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(2):\n",
    "\n",
    "    img, _ = imagens_treino[i]\n",
    "    img_mean = img.mean(dim=[1,2], keepdims=True)\n",
    "\n",
    "    # Shift da imagem por 1 pixel\n",
    "    SHIFT = 1\n",
    "    img_shifted = torch.roll(img, shifts = SHIFT, dims = 1)\n",
    "    img_shifted = torch.roll(img_shifted, shifts = SHIFT, dims = 2)\n",
    "    img_shifted[:,:1,:] = img_mean\n",
    "    img_shifted[:,:,:1] = img_mean\n",
    "    compare_imgs(img, img_shifted, \"Shifted -\")\n",
    "\n",
    "    # Definir metade da imagem para zero\n",
    "    img_masked = img.clone()\n",
    "    img_masked[:,:img_masked.shape[1]//2,:] = img_mean\n",
    "    compare_imgs(img, img_masked, \"Masked -\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o Modelo\n",
    "\n",
    "Durante o treinamento, queremos acompanhar o progresso do aprendizado vendo as reconstruções feitas pelo nosso modelo. Para isso, implementamos um objeto callback no PyTorch Lightning que adicionará reconstruções a cada $N$ épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback\n",
    "class GenerateCallback(pl.Callback):\n",
    "    \n",
    "    def __init__(self, input_imgs, every_n_epochs=1):\n",
    "        super().__init__()\n",
    "        self.input_imgs = input_imgs \n",
    "        self.every_n_epochs = every_n_epochs \n",
    "        \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        \n",
    "        if trainer.current_epoch % self.every_n_epochs == 0:\n",
    "            \n",
    "            # Reconstrói a imagem\n",
    "            input_imgs = self.input_imgs.to(pl_module.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                pl_module.eval()\n",
    "                reconst_imgs = pl_module(input_imgs)\n",
    "                pl_module.train()\n",
    "            \n",
    "            # Plot e log\n",
    "            imgs = torch.stack([input_imgs, reconst_imgs], dim = 1).flatten(0,1)\n",
    "            grid = torchvision.utils.make_grid(imgs, nrow = 2, normalize = True, range = (-1,1))\n",
    "            trainer.logger.experiment.add_image(\"Reconstructions\", grid, global_step = trainer.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora escreveremos uma função de treinamento que nos permite treinar o modelo com dimensionalidade latente diferente e retornar a pontuação em validação e teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treinamento\n",
    "def treina_modelo(latent_dim):\n",
    "    \n",
    "    trainer = pl.Trainer(default_root_dir = os.path.join(CHECKPOINT_PATH, f\"cifar10_{latent_dim}\"), \n",
    "                         accelerator = \"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices = 1,\n",
    "                         max_epochs = 500, \n",
    "                         callbacks = [ModelCheckpoint(save_weights_only = True),\n",
    "                                      GenerateCallback(get_train_images(8), every_n_epochs = 10),\n",
    "                                      LearningRateMonitor(\"epoch\")])\n",
    "    \n",
    "    trainer.logger._log_graph = True         \n",
    "    trainer.logger._default_hp_metric = None \n",
    "    \n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"cifar10_{latent_dim}.ckpt\")\n",
    "    \n",
    "    # Se encontra o modelo já treinado, ele será usado. Caso contrário, será feito o treinamento.\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Encontrei o modelo treinado. Carregando...\")\n",
    "        model = DeepAutoencoder.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        print(\"Iniciando o treinamento...\")\n",
    "        model = DeepAutoencoder(base_channel_size = 32, latent_dim = latent_dim)\n",
    "        trainer.fit(model, loader_treino, loader_valid)\n",
    "    \n",
    "\n",
    "    val_result = trainer.test(model, loader_valid, verbose = False)\n",
    "    test_result = trainer.test(model, loader_teste, verbose = False)\n",
    "    \n",
    "    result = {\"teste\": test_result, \"valid\": val_result}\n",
    "    \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparando a Dimensionalidade Latente\n",
    "\n",
    "Ao treinar um autoencoder, precisamos escolher uma dimensionalidade para a representação latente $z$. \n",
    "\n",
    "Quanto maior a dimensionalidade latente, melhor esperamos que seja a reconstrução. No entanto, a ideia dos autoencoders é *comprimir* os dados. Portanto, também estamos interessados em manter a dimensionalidade baixa. \n",
    "\n",
    "Para encontrar a melhor compensação, podemos treinar vários modelos com diferentes dimensionalidades latentes. A entrada original tem $32\\times 32\\times 3 = 3072$ pixels. Tendo isso em mente, uma escolha razoável para a dimensionalidade latente pode estar entre 64 e 384:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nível de precisão das operações de multiplicação\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário\n",
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop\n",
    "for latent_dim in [64, 128, 256, 384]:\n",
    "    model_ld, result_ld = treina_modelo(latent_dim)\n",
    "    model_dict[latent_dim] = {\"model\": model_ld, \"result\": result_ld}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de treinar os modelos, podemos plotar a perda de reconstrução sobre a dimensionalidade latente para obter uma intuição de como essas duas propriedades estão correlacionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = sorted([k for k in model_dict])\n",
    "val_scores = [model_dict[k][\"result\"][\"valid\"][0][\"test_loss\"] for k in latent_dims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = plt.figure(figsize = (6,4))\n",
    "plt.plot(latent_dims, \n",
    "         val_scores, '--', \n",
    "         color = \"#000\", \n",
    "         marker = \"*\", \n",
    "         markeredgecolor = \"#000\", \n",
    "         markerfacecolor = \"y\", \n",
    "         markersize = 16)\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks(latent_dims, labels=latent_dims)\n",
    "plt.title(\"Erro de reconstrução sobre dimensionalidade latente\", fontsize=14)\n",
    "plt.xlabel(\"Dimensionalidade latente\")\n",
    "plt.ylabel(\"Erro de reconstrução\")\n",
    "plt.minorticks_off()\n",
    "plt.ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperávamos inicialmente, a perda de reconstrução diminui com o aumento da dimensionalidade latente. \n",
    "\n",
    "Para nosso modelo e configuração, as duas propriedades parecem ser exponencialmente correlacionadas. Para entender o que significam essas diferenças no erro de reconstrução, podemos visualizar reconstruções de exemplo dos quatro modelos. Para simplificar, visualizamos quatro imagens de treinamento do CIFAR10 que já vimos antes. Para modelos maiores que podem ter overfit, é recomendável usar imagens do conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de visualização\n",
    "def visualize_reconstructions(model, input_imgs):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        reconst_imgs = model(input_imgs.to(model.device))\n",
    "    \n",
    "    reconst_imgs = reconst_imgs.cpu()\n",
    "    \n",
    "    # Plot\n",
    "    imgs = torch.stack([input_imgs, reconst_imgs], dim = 1).flatten(0,1)\n",
    "    grid = torchvision.utils.make_grid(imgs, nrow = 4, normalize = True, range = (-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.title(f\"Reconstruído a partir de {model.hparams.latent_dim} latentes\")\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgs = get_train_images(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop\n",
    "for latent_dim in model_dict:\n",
    "    visualize_reconstructions(model_dict[latent_dim][\"model\"], input_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, a menor dimensionalidade latente só pode salvar informações sobre a forma e a cor do objeto, mas a imagem reconstruída é extremamente embaçada e é difícil reconhecer o objeto original na reconstrução. \n",
    "\n",
    "Com 128 recursos, podemos reconhecer algumas formas novamente, embora a imagem permaneça embaçada. Os modelos com as bidimensionalidades mais altas reconstroem as imagens muito bem. A diferença entre 256 e 384 é marginal à primeira vista, mas pode ser notada ao comparar, por exemplo, os fundos da primeira imagem (as características 384 modelam mais o padrão do que 256)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando Limitações do Modelo\n",
    "\n",
    "Antes de continuar com as aplicações do Autoencoder, podemos explorar algumas limitações do nosso modelo. \n",
    "\n",
    "Por exemplo, o que acontece se tentarmos reconstruir uma imagem que está claramente fora da distribuição do nosso conjunto de dados? Esperamos que o decodificador tenha aprendido alguns padrões comuns no conjunto de dados e, portanto, pode falhar em reconstruir imagens que não seguem esses padrões.\n",
    "\n",
    "A primeira experiência que podemos tentar é reconstruir o ruído. Criamos, portanto, duas imagens cujos pixels são amostrados aleatoriamente a partir de uma distribuição uniforme sobre os valores dos pixels e visualizamos a reconstrução do modelo (fique à vontade para testar diferentes dimensionalidades latentes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_imgs = torch.rand(2, 3, 32, 32) * 2 - 1\n",
    "visualize_reconstructions(model_dict[256][\"model\"], rand_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reconstrução do ruído é bastante pobre e parece apresentar alguns padrões grosseiros. Como a entrada não segue os padrões do conjunto de dados CIFAR, o modelo tem problemas para reconstruí-la com precisão.\n",
    "\n",
    "Também podemos verificar o quão bem o modelo pode reconstruir outros padrões codificados manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_imgs = torch.zeros(4, 3, 32, 32)\n",
    "\n",
    "# Canal de cor única\n",
    "plain_imgs[1,0] = 1 \n",
    "\n",
    "# Checkboard\n",
    "plain_imgs[2,:,:16,:16] = 1\n",
    "plain_imgs[2,:,16:,16:] = -1\n",
    "\n",
    "# Progressão de cores\n",
    "xx, yy = torch.meshgrid(torch.linspace(-1,1,32), torch.linspace(-1,1,32))\n",
    "plain_imgs[3,0,:,:] = xx\n",
    "plain_imgs[3,1,:,:] = yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_reconstructions(model_dict[256][\"model\"], plain_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens simples e constantes são reconstruídas relativamente bem, embora o canal de cor única contenha algum ruído perceptível. As bordas duras do padrão do Checkboard não são tão nítidas quanto o pretendido, assim como a progressão de cores, porque esses padrões nunca ocorrem nas imagens do mundo real do CIFAR.\n",
    "\n",
    "Em geral, os autoencoders tendem a falhar na reconstrução de ruídos de alta frequência (ou seja, grandes mudanças repentinas em poucos pixels) devido à escolha do MSE como função de perda. \n",
    "\n",
    "Pequenos desalinhamentos no decodificador podem levar a grandes perdas para que o modelo se ajuste ao valor/média esperado nessas regiões. Para ruídos de baixa frequência, um desalinhamento de alguns pixels não resulta em uma grande diferença na imagem original. No entanto, quanto maior a dimensionalidade latente se torna, mais desse ruído de alta frequência pode ser reconstruído com precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando Novas Imagens\n",
    "\n",
    "o que aconteceria se realmente inseríssemos um vetor latente amostrado aleatoriamente no decodificador? Vamos descobrir abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dict[256][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors = torch.randn(8, model.hparams.latent_dim, device=model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    imgs = model.decoder(latent_vectors)\n",
    "    imgs = imgs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid\n",
    "grid = torchvision.utils.make_grid(imgs, nrow = 4, normalize = True, range = (-1,1), pad_value = 0.5)\n",
    "grid = grid.permute(1, 2, 0)\n",
    "plt.figure(figsize = (8,5))\n",
    "plt.imshow(grid)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, as imagens geradas parecem mais arte do que imagens realistas. Como o autoencoder foi autorizado a estruturar o espaço latente da maneira que melhor se adaptasse à reconstrução, não há incentivo para mapear todos os vetores latentes possíveis para imagens realistas. Além disso, a distribuição no espaço latente é desconhecida para nós e não segue necessariamente uma distribuição normal multivariada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando Imagens Visualmente Semelhantes\n",
    "\n",
    "Uma aplicação dos autoencoders é construir um mecanismo de pesquisa baseado em imagens para recuperar imagens visualmente semelhantes. Isso pode ser feito representando todas as imagens como sua dimensionalidade latente e encontrando as imagens $K$ mais próximas neste domínio. \n",
    "\n",
    "O primeiro passo para tal mecanismo de busca é codificar todas as imagens em $z$. A seguir, usaremos o conjunto de treinamento como corpus de busca e o conjunto de teste como consultas ao sistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se você quiser tentar uma dimensionalidade latente diferente, mude aqui!\n",
    "model = model_dict[128][\"model\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_imgs(model, data_loader):\n",
    "    \n",
    "    # Encode de todas as imagens no data_laoder usando o modelo e retorna imagens e codificações\n",
    "    img_list, embed_list = [], []\n",
    "    model.eval()\n",
    "    for imgs, _ in tqdm(data_loader, desc = \"Encoding images\", leave = False):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z = model.encoder(imgs.to(model.device))\n",
    "        \n",
    "        img_list.append(imgs)\n",
    "        \n",
    "        embed_list.append(z)\n",
    "    \n",
    "    return (torch.cat(img_list, dim = 0), torch.cat(embed_list, dim = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_embeds = embed_imgs(model, loader_treino)\n",
    "test_img_embeds = embed_imgs(model, loader_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois de codificar todas as imagens, só precisamos escrever uma função que encontre as imagens $K$ mais próximas e retorne. Usamos a distância euclidiana aqui, mas outras distâncias semelhantes ao cosseno também podem ser usadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função do sistema de similaridade\n",
    "def find_similar_images(query_img, query_z, key_embeds, K = 8):\n",
    "    dist = torch.cdist(query_z[None,:], key_embeds[1], p = 2)\n",
    "    dist = dist.squeeze(dim=0)\n",
    "    dist, indices = torch.sort(dist)\n",
    "    imgs_to_display = torch.cat([query_img[None], key_embeds[0][indices[:K]]], dim = 0)\n",
    "    grid = torchvision.utils.make_grid(imgs_to_display, nrow = K+1, normalize = True, range = (-1,1))\n",
    "    grid = grid.permute(1, 2, 0)\n",
    "    plt.figure(figsize = (12,3))\n",
    "    plt.imshow(grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot das imagens mais próximas para as primeiras N imagens de teste como exemplo\n",
    "for i in range(8):\n",
    "    find_similar_images(test_img_embeds[0][i], test_img_embeds[1][i], key_embeds = train_img_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base em nosso autoencoder, vemos que podemos recuperar muitas imagens semelhantes para a entrada de teste. \n",
    "\n",
    "Em particular, na linha 4, podemos identificar que algumas imagens de teste podem não ser tão diferentes do conjunto de treinamento quanto pensávamos (mesmo pôster, apenas escala/escala de cores diferentes). \n",
    "\n",
    "Também vemos que, embora não tenhamos dado nenhum rótulo ao modelo, ele pode agrupar diferentes classes em diferentes partes do espaço latente (avião + navio, animais, etc.). É por isso que os autoencoders também podem ser usados como uma estratégia de pré-treinamento para redes profundas, especialmente quando temos um grande conjunto de imagens não rotuladas (geralmente o caso). \n",
    "\n",
    "No entanto, deve-se observar que o plano de fundo ainda desempenha um papel importante nos autoencoders, mas não na classificação. Portanto, não obtemos clusters \"perfeitos\" e precisamos ajustar esses modelos para classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
